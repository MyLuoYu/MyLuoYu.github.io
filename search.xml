<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Linux常用命令</title>
    <url>/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>    本文撰写的目的是为了使刚接触Linux的小白更好的操作使用Linux，以及作为个人的备忘录。文章介绍的命令是本在Linux系统日常使用中常用到的，或者是在服务器上开发所用到的高频率命令。</p>
<p>    点击下载👉<a href="">PDF下载</a></p>
<span id="more"></span>

<h1 id="切换目录：cd"><a href="#切换目录：cd" class="headerlink" title="切换目录：cd"></a>切换目录：cd</h1><h2 id="cd命令格式"><a href="#cd命令格式" class="headerlink" title="cd命令格式"></a>cd命令格式</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> [目录路径]</span><br></pre></td></tr></table></figure>

<h2 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h2><p><strong>[目录路径]</strong> 可以是绝对路径也可以是相对路径，常见的相对路径有：</p>
<ul>
<li><p>.&#x2F;    表示当前目录</p>
</li>
<li><p>..&#x2F;   表示上一级目录</p>
</li>
<li><p>~    表示用户主目录（&#x2F;home&#x2F;user）</p>
</li>
<li><p>-    表示上一次工作路径</p>
</li>
</ul>
<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><p>进入根目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /</span><br></pre></td></tr></table></figure>

<p>进入 “home” 目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line"><span class="built_in">cd</span></span><br></pre></td></tr></table></figure>

<p>进入上一次工作路径</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> -</span><br></pre></td></tr></table></figure>

<p>进入上一级目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ../</span><br></pre></td></tr></table></figure>

<h1 id="查询当前目录路径：pwd"><a href="#查询当前目录路径：pwd" class="headerlink" title="查询当前目录路径：pwd"></a>查询当前目录路径：pwd</h1><blockquote>
<p>这是一个相当常用的命令，一般在写配置文件时常常要指定一个目录或者文件。<br>所以，会在写文件时候提前wpd显示目录路径进行复制。</p>
</blockquote>
<h2 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">pwd</span></span><br></pre></td></tr></table></figure>

<h2 id="拓展-1"><a href="#拓展-1" class="headerlink" title="拓展"></a>拓展</h2><p>在<em>终端</em>中的<u><strong>复制</strong></u>快捷键是：Ctrl + Shift + C<br>在<em>终端</em>中的<strong>粘贴</strong>快捷键是：Ctrl + Shift + V</p>
<h1 id="查询文件命令：ls"><a href="#查询文件命令：ls" class="headerlink" title="查询文件命令：ls"></a>查询文件命令：ls</h1><h2 id="命令格式-1"><a href="#命令格式-1" class="headerlink" title="命令格式"></a>命令格式</h2><p>不加 <strong>[目录路径]</strong> 默认为当前目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> [目录路径]</span><br></pre></td></tr></table></figure>

<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><ul>
<li><strong>-l</strong>：除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来</li>
<li><strong>-a</strong>：显示所有目录和文件（包括隐藏目录）</li>
<li><strong>-A</strong>：列出除.及..的其它文件</li>
<li><strong>-r</strong>：反序排列</li>
<li><strong>-S</strong>：以文件大小排序</li>
</ul>
<h2 id="案例-1"><a href="#案例-1" class="headerlink" title="案例"></a>案例</h2><p>按大小反序显示文件详细信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> -lrS</span><br></pre></td></tr></table></figure>

<p>按修改时间反序排序，并显示文件详细信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> -lrt</span><br></pre></td></tr></table></figure>

<p>列出当前目录中所有以”t”开头的目录的详细内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> -l t*</span><br></pre></td></tr></table></figure>

<p>列出文件绝对路径（不包含隐藏文件）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> | sed <span class="string">&quot;s:^:`pwd`/:&quot;</span></span><br></pre></td></tr></table></figure>

<h1 id="创建目录-文件夹-：mkdir"><a href="#创建目录-文件夹-：mkdir" class="headerlink" title="创建目录(文件夹)：mkdir"></a>创建目录(文件夹)：mkdir</h1><h2 id="命令格式-2"><a href="#命令格式-2" class="headerlink" title="命令格式"></a>命令格式</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> [参数] [目录名]</span><br></pre></td></tr></table></figure>

<h2 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h2><ul>
<li><strong>-m</strong>   ：对新建目录设置存取权限，也可以用 chmod 命令设置</li>
<li><strong>-p</strong>    ：可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后，系统将自动建立好那些尚不在的目录，即一次可以建立多个目录。</li>
</ul>
<h2 id="案例-2"><a href="#案例-2" class="headerlink" title="案例"></a>案例</h2><p>当前工作目录下创建名为 t的文件夹</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> t</span><br></pre></td></tr></table></figure>

<p>在 tmp 目录下创建路径为 test&#x2F;t1&#x2F;t 的目录，若不存在，则创建</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /tmp/test/t1/t</span><br></pre></td></tr></table></figure>

<h1 id="删除命令：rm"><a href="#删除命令：rm" class="headerlink" title="删除命令：rm"></a>删除命令：rm</h1><h2 id="命令格式-3"><a href="#命令格式-3" class="headerlink" title="命令格式"></a>命令格式</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> [选项] 文件(目录)…</span><br></pre></td></tr></table></figure>

<h2 id="参数-2"><a href="#参数-2" class="headerlink" title="参数"></a>参数</h2><ul>
<li><p><strong>-r</strong>    ：删除一个目录中的一个或多个文件或目录，如果没有使用 -r 选项，则 rm 不会删除目</p>
</li>
<li><p><strong>-i</strong>    ：删除任何文件，删除前逐一询问确认</p>
</li>
<li><p><strong>-rf</strong>    ：删除子目录及子目录中所有档案删除，并且不用确认</p>
</li>
</ul>
<h2 id="案例-3"><a href="#案例-3" class="headerlink" title="案例"></a>案例</h2><p>删除任何 .log结尾的文件，删除前逐一询问确认</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> -i *.<span class="built_in">log</span></span><br></pre></td></tr></table></figure>

<p>删除 test 子目录及子目录中所有档案删除，并且不用一一确认：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<p>删除以 -f 开头的文件</p>
<blockquote>
<p>文件（目录）以 “-”开头会让命令误认为是参数，所以加上“–“进行分隔</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> -- -f*</span><br></pre></td></tr></table></figure>

<h1 id="移动-重命名-：mv"><a href="#移动-重命名-：mv" class="headerlink" title="移动(重命名)：mv"></a>移动(重命名)：mv</h1><blockquote>
<p>移动文件或修改文件名，根据第二参数类型（如目录，则移动文件；如为文件则重命令该文件）。</p>
<p>当第二个参数为目录时，第一个参数可以是多个以空格分隔的文件或目录，然后移动第一个参数指定的多个文件到第二个参数指定的目录中。</p>
</blockquote>
<h2 id="命令格式-4"><a href="#命令格式-4" class="headerlink" title="命令格式"></a>命令格式</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> [文件(目录)] [文件(目录)]</span><br></pre></td></tr></table></figure>

<h2 id="参数-3"><a href="#参数-3" class="headerlink" title="参数"></a>参数</h2><ul>
<li><strong>-i</strong>    :是否询问覆盖</li>
</ul>
<h2 id="案例-4"><a href="#案例-4" class="headerlink" title="案例"></a>案例</h2><p>将文件 test.log 重命名为 test1.txt</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> test.log test1.txt</span><br></pre></td></tr></table></figure>

<p>将文件 log1.txt,log2.txt,log3.txt 移动到根的 test3 目录中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> llog1.txt log2.txt log3.txt /test3</span><br></pre></td></tr></table></figure>

<p>将文件 file1 改名为 file2，如果 file2 已经存在，则询问是否覆盖</p>
<blockquote>
<p>不加参数-i则强制覆盖</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> -i log1.txt log2.txt</span><br></pre></td></tr></table></figure>

<p>移动当前文件夹下的所有文件到上一级目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> * ../</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>IT知识</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Manjaro-i3wm安装</title>
    <url>/Manjaro-i3wm%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>    详细介绍Manjaro系统的i3wm桌面环境的安装与踩坑。</p>
<p>    点击下载👉<a href="">PDF下载</a></p>
<span id="more"></span>

<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>manjaro i3其实是i3-gaps,i3wm的加强版,主要能使窗口间有间隔！而且下载完整版安装很多软件及配置，快捷键都默认设置好了  。<br>系统镜像在官网下载的社区版本manjaro+i3</p>
<h2 id="ISO镜像下载"><a href="#ISO镜像下载" class="headerlink" title="ISO镜像下载"></a>ISO镜像下载</h2><p><a href="https://manjaro.org/download/">下载网址</a>：<a href="https://manjaro.org/download/">https://manjaro.org/download/</a></p>
<p><img src="/Manjaro-i3wm%E5%AE%89%E8%A3%85/2022-08-13-21-01-55-image.png"></p>
<h2 id="刻录U盘"><a href="#刻录U盘" class="headerlink" title="刻录U盘"></a>刻录U盘</h2><h3 id="下载U盘刻录工具Rufus"><a href="#下载U盘刻录工具Rufus" class="headerlink" title="下载U盘刻录工具Rufus"></a>下载U盘刻录工具Rufus</h3><p><a href="https://rufus.en.softonic.com/">下载地址</a>：<a href="https://rufus.en.softonic.com/">https://rufus.en.softonic.com/</a></p>
<h3 id="Rufus使用"><a href="#Rufus使用" class="headerlink" title="Rufus使用"></a>Rufus使用</h3><h2 id="进入BIOS启动安装程序"><a href="#进入BIOS启动安装程序" class="headerlink" title="进入BIOS启动安装程序"></a>进入BIOS启动安装程序</h2><h2 id="安装Manjaro"><a href="#安装Manjaro" class="headerlink" title="安装Manjaro"></a>安装Manjaro</h2>]]></content>
      <categories>
        <category>IT知识</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop搭建调优笔记</title>
    <url>/Hadoop%E6%90%AD%E5%BB%BA%E8%B0%83%E4%BC%98%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>    使用Linux（manjaro）系统，从虚拟机开始搭建Hadoop平台以及Hadoop的调优。内容简单详细</p>
<p>    点击下载👉<a href="">PDF下载</a></p>
<span id="more"></span>

<h2 id="Hadoop环境搭建"><a href="#Hadoop环境搭建" class="headerlink" title="Hadoop环境搭建"></a>Hadoop环境搭建</h2><h3 id="准备模板机"><a href="#准备模板机" class="headerlink" title="准备模板机"></a>准备模板机</h3><blockquote>
<p>选择系统：Centos最小化换安装</p>
<p>以下操作均处于user（luo）用户下进行，操作必须保持操作用户统一。</p>
</blockquote>
<h4 id="user（luo）用户权限设置"><a href="#user（luo）用户权限设置" class="headerlink" title="user（luo）用户权限设置"></a>user（luo）用户权限设置</h4><blockquote>
<p>配置luo用户具有root权限，方便后期加sudo执行root权限的命令</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/sudoers</span><br></pre></td></tr></table></figure>

<blockquote>
<p>修改&#x2F;etc&#x2F;sudoers文件，在%wheel这行下面添加一行，如下所示：</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Allow root to run any commands anywhere</span></span><br><span class="line">root    ALL=(ALL)     ALL</span><br><span class="line"></span><br><span class="line"><span class="comment">## Allows people in group wheel to run all commands</span></span><br><span class="line">%wheel  ALL=(ALL)       ALL</span><br><span class="line">luo   ALL=(ALL)     NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<h4 id="下载vim、net-tools、rsync"><a href="#下载vim、net-tools、rsync" class="headerlink" title="下载vim、net-tools、rsync"></a>下载vim、net-tools、rsync</h4><blockquote>
<p>vim用于编写文件</p>
<p>rsync用于传输文件</p>
<p>net-tools用于查看网络</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum install net-tools.x86_64 </span><br><span class="line">sudo yum install rsync </span><br><span class="line">sudo yum install vim</span><br></pre></td></tr></table></figure>

<h4 id="配置静态网络"><a href="#配置静态网络" class="headerlink" title="配置静态网络"></a>配置静态网络</h4><blockquote>
<p>系统版本不同ifcfg-eth0文件可能存在不一致</p>
<p>如ifcfg-ens33等，但文件内容相同</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/sysconfig/network-scripts/ifcfg-eth0 </span><br></pre></td></tr></table></figure>

<blockquote>
<p>BOOTPROTO&#x3D;”static”    网络设置为静态</p>
<p>IPADDR&#x3D;192.168.122.100    ip设置    网段必需一致（当前网段为122）<br>GATEWAY&#x3D;192.168.122.1    网关设置<br>DNS1&#x3D;192.168.122.1    DNS设置</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">TYPE=<span class="string">&quot;Ethernet&quot;</span></span><br><span class="line">PROXY_METHOD=<span class="string">&quot;none&quot;</span></span><br><span class="line">BROWSER_ONLY=<span class="string">&quot;no&quot;</span></span><br><span class="line">BOOTPROTO=<span class="string">&quot;static&quot;</span></span><br><span class="line">DEFROUTE=<span class="string">&quot;yes&quot;</span></span><br><span class="line">IPV4_FAILURE_FATAL=<span class="string">&quot;no&quot;</span></span><br><span class="line">IPV6INIT=<span class="string">&quot;yes&quot;</span></span><br><span class="line">IPV6_AUTOCONF=<span class="string">&quot;yes&quot;</span></span><br><span class="line">IPV6_DEFROUTE=<span class="string">&quot;yes&quot;</span></span><br><span class="line">IPV6_FAILURE_FATAL=<span class="string">&quot;no&quot;</span></span><br><span class="line">IPV6_ADDR_GEN_MODE=<span class="string">&quot;stable-privacy&quot;</span></span><br><span class="line">NAME=<span class="string">&quot;eth0&quot;</span></span><br><span class="line">UUID=<span class="string">&quot;0980c27a-83b0-40da-a492-e1ea5164aa1c&quot;</span></span><br><span class="line">DEVICE=<span class="string">&quot;eth0&quot;</span></span><br><span class="line">ONBOOT=<span class="string">&quot;yes&quot;</span></span><br><span class="line"></span><br><span class="line">IPADDR=192.168.122.100</span><br><span class="line">GATEWAY=192.168.122.1</span><br><span class="line">DNS1=192.168.122.1</span><br></pre></td></tr></table></figure>

<blockquote>
<p>重启IP网络</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo service network restart</span><br></pre></td></tr></table></figure>

<h4 id="配置映射和主机名"><a href="#配置映射和主机名" class="headerlink" title="配置映射和主机名"></a>配置映射和主机名</h4><blockquote>
<p>进入hosts文件编辑</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure>

<blockquote>
<p>在文档中添加，将来要加入集群的ip及其名称</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.122.100 hadoop100</span><br><span class="line">192.168.122.102 hadoop102</span><br><span class="line">192.168.122.103 hadoop103</span><br><span class="line">192.168.122.104 hadoop104</span><br></pre></td></tr></table></figure>

<blockquote>
<p>进入hostname文件编辑</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/hostname</span><br></pre></td></tr></table></figure>

<blockquote>
<p>删除原先主机名称</p>
<p>修改为自定义主机名称</p>
<p>本机为hadoop100</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop100</span><br></pre></td></tr></table></figure>

<h4 id="关闭防火墙和开机自启"><a href="#关闭防火墙和开机自启" class="headerlink" title="关闭防火墙和开机自启"></a>关闭防火墙和开机自启</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service</span><br></pre></td></tr></table></figure>

<h4 id="创建目录并修改目录所有者"><a href="#创建目录并修改目录所有者" class="headerlink" title="创建目录并修改目录所有者"></a>创建目录并修改目录所有者</h4><blockquote>
<p>创建目录</p>
<p>module：存放软件</p>
<p>software：存放软件包</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">mkdir</span> /opt/module/ /opt/software/</span><br></pre></td></tr></table></figure>

<blockquote>
<p>修改目录所有者</p>
<p>当前用户为luo</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">chown</span> luo:luo /opt/module/ /opt/software/</span><br></pre></td></tr></table></figure>

<h4 id="安装jdk和hadoop及其环境配置"><a href="#安装jdk和hadoop及其环境配置" class="headerlink" title="安装jdk和hadoop及其环境配置"></a>安装jdk和hadoop及其环境配置</h4><blockquote>
<p>创建配置文件</p>
<p>系统中的profile配置文件会遍历profile.d下的所有.sh文件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<blockquote>
<p>编写配置文件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk-11</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-3.3.1</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure>

<h3 id="免密登录"><a href="#免密登录" class="headerlink" title="免密登录"></a>免密登录</h3><blockquote>
<p>环境：</p>
<ol>
<li>3台由hadoop100克隆的虚拟机</li>
<li>配置3台虚拟机的静态网络和主机名（102、103、104）</li>
<li>接下来的操作以hadoop102为主机</li>
<li>hadoopxxx是hosts的映射ip</li>
</ol>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line">ssh-copy-id hadoop102</span><br><span class="line">ssh-copy-id hadoop103</span><br><span class="line">ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure>

<h3 id="Hadoop集群配置"><a href="#Hadoop集群配置" class="headerlink" title="Hadoop集群配置"></a>Hadoop集群配置</h3><blockquote>
<p>hadoop有以下4个文件需要配置：</p>
<ol>
<li>core-site.xml</li>
<li>hdfs-site.xml</li>
<li>mapred-site.xml</li>
<li>yarn-site.xml</li>
<li>workers</li>
</ol>
<p>进入文件所在目录进行配置</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/module/hadoop-3.3.1/etc/hadoop/</span><br></pre></td></tr></table></figure>

<blockquote>
<p>在</p>
<configuration>

</configuration>

<p>标签内填写配置内容</p>
<p>必需在标签内填写配置内容！</p>
</blockquote>
<h4 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.3.1/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为luo --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>luo<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- nn web端访问地址--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 2nn web端访问地址--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR走shuffle --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启日志聚集功能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop102:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="workers"><a href="#workers" class="headerlink" title="workers"></a>workers</h4><blockquote>
<p>workers填写的是集群主机的映射</p>
<p>不能存在多余的字符，如空格或者回车</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure>

<h3 id="分发hadoop以及启动"><a href="#分发hadoop以及启动" class="headerlink" title="分发hadoop以及启动"></a>分发hadoop以及启动</h3><blockquote>
<p>为方便管理，使用了脚本进行分发与启动</p>
<ol>
<li>jpsall    （查看集群状态）  </li>
<li>myhadoop.sh     （对集群操作管理）</li>
<li>xsync        （分发脚本）</li>
</ol>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">xsync /opt/module/hadoop-3.3.1/</span><br><span class="line">myhadoop.sh start</span><br></pre></td></tr></table></figure>

<h3 id="格式化NameNode"><a href="#格式化NameNode" class="headerlink" title="格式化NameNode"></a>格式化NameNode</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/module/hadoop-3.3.1</span><br><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>

<h3 id="编写脚本"><a href="#编写脚本" class="headerlink" title="编写脚本"></a>编写脚本</h3><blockquote>
<p>centos系统&#x2F;home&#x2F;user(luo)&#x2F;bin目录默认添加到PATH，其他版本需要手动添加环境PATH</p>
<p>在必需在创建的bin目录下编写脚本 或者 自己添加到PATH的目录</p>
</blockquote>
<p>创建bin目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> ~/bin</span><br></pre></td></tr></table></figure>

<h4 id="jpsall"><a href="#jpsall" class="headerlink" title="jpsall"></a>jpsall</h4><blockquote>
<p>映射：按要求更改</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> =============== <span class="variable">$host</span> ===============</span><br><span class="line">        ssh <span class="variable">$host</span> jps</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h4 id="myhadoop-sh"><a href="#myhadoop-sh" class="headerlink" title="myhadoop.sh"></a>myhadoop.sh</h4><blockquote>
<p>映射、路径：按要求更改</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;No Args Input...&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> ;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 启动 hadoop集群 ===================&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 hdfs ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.3.1/sbin/start-dfs.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 yarn ---------------&quot;</span></span><br><span class="line">        ssh hadoop103 <span class="string">&quot;/opt/module/hadoop-3.3.1/sbin/start-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 historyserver ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.3.1/bin/mapred --daemon start historyserver&quot;</span></span><br><span class="line">;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 关闭 hadoop集群 ===================&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 historyserver ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.3.1/bin/mapred --daemon stop historyserver&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 yarn ---------------&quot;</span></span><br><span class="line">        ssh hadoop103 <span class="string">&quot;/opt/module/hadoop-3.3.1/sbin/stop-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 hdfs ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.3.1/sbin/stop-dfs.sh&quot;</span></span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Input Args Error...&quot;</span></span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<h4 id="xsync"><a href="#xsync" class="headerlink" title="xsync"></a>xsync</h4><blockquote>
<p>映射：按要求更改</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1. 判断参数个数</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> Not Enough Arguement!</span><br><span class="line">    <span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2. 遍历集群所有机器</span></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> ====================  <span class="variable">$host</span>  ====================</span><br><span class="line">    <span class="comment">#3. 遍历所有目录，挨个发送</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> <span class="variable">$@</span></span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="comment">#4. 判断文件是否存在</span></span><br><span class="line">        <span class="keyword">if</span> [ -e <span class="variable">$file</span> ]</span><br><span class="line">            <span class="keyword">then</span></span><br><span class="line">                <span class="comment">#5. 获取父目录</span></span><br><span class="line">                pdir=$(<span class="built_in">cd</span> -P $(<span class="built_in">dirname</span> <span class="variable">$file</span>); <span class="built_in">pwd</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment">#6. 获取当前文件的名称</span></span><br><span class="line">                fname=$(<span class="built_in">basename</span> <span class="variable">$file</span>)</span><br><span class="line">                ssh <span class="variable">$host</span> <span class="string">&quot;mkdir -p <span class="variable">$pdir</span>&quot;</span></span><br><span class="line">                rsync -av <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$host</span>:<span class="variable">$pdir</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="variable">$file</span> does not exists!</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h4 id="kvm"><a href="#kvm" class="headerlink" title="kvm"></a>kvm</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#/bin/zsh</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;-vm&quot;</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="variable">$2</span> <span class="keyword">in</span></span><br><span class="line">    <span class="string">&quot;start&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 启动虚拟机管理后台服务 ===================&quot;</span></span><br><span class="line">        sudo systemctl start libvirtd</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 启动 default NAT 网络 ===================&quot;</span></span><br><span class="line">        sudo virsh net-start default</span><br><span class="line">    ;;</span><br><span class="line">    <span class="string">&quot;status&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 所以虚拟机状态 ===================&quot;</span></span><br><span class="line">        sudo virsh list --all</span><br><span class="line">    ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line">;;</span><br><span class="line"><span class="string">&quot;-hadoop&quot;</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="variable">$2</span> <span class="keyword">in</span></span><br><span class="line">    <span class="string">&quot;start&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 开启虚拟机：hadoop102 ===================&quot;</span></span><br><span class="line">        sudo virsh start hadoop102</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 开启虚拟机：hadoop103 ===================&quot;</span></span><br><span class="line">        sudo virsh start hadoop103</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 开启虚拟机：hadoop104 ===================&quot;</span></span><br><span class="line">        sudo virsh start hadoop104</span><br><span class="line"></span><br><span class="line">        <span class="built_in">sleep</span> 15s</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 hdfs ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.3.1/sbin/start-dfs.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 yarn ---------------&quot;</span></span><br><span class="line">        ssh hadoop103 <span class="string">&quot;/opt/module/hadoop-3.3.1/sbin/start-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 historyserver ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.3.1/bin/mapred --daemon start historyserver&quot;</span></span><br><span class="line">    ;;</span><br><span class="line">    <span class="string">&quot;stop&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 historyserver ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.3.1/bin/mapred --daemon stop historyserver&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 yarn ---------------&quot;</span></span><br><span class="line">        ssh hadoop103 <span class="string">&quot;/opt/module/hadoop-3.3.1/sbin/stop-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 hdfs ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.3.1/sbin/stop-dfs.sh&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 关闭虚拟机：hadoop102 ===================&quot;</span></span><br><span class="line">        sudo virsh shutdown hadoop102</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 关闭虚拟机：hadoop103 ===================&quot;</span></span><br><span class="line">        sudo virsh shutdown hadoop103</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 关闭虚拟机：hadoop104 ===================&quot;</span></span><br><span class="line">        sudo virsh shutdown hadoop104</span><br><span class="line">    ;;</span><br><span class="line">    <span class="string">&quot;status&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> host <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">            <span class="built_in">echo</span> =============== <span class="variable">$host</span> ===============</span><br><span class="line">            ssh <span class="variable">$host</span> jps</span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">    ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Input Args Error...&quot;</span></span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<h4 id="赋予权限"><a href="#赋予权限" class="headerlink" title="赋予权限"></a>赋予权限</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x jpsall</span><br><span class="line"><span class="built_in">chmod</span> +x myhadoop.sh</span><br><span class="line"><span class="built_in">chmod</span> +x xsync</span><br></pre></td></tr></table></figure>

<h2 id="yarn笔记"><a href="#yarn笔记" class="headerlink" title="yarn笔记"></a>yarn笔记</h2><h3 id="Yarn的工作机制"><a href="#Yarn的工作机制" class="headerlink" title="Yarn的工作机制"></a>Yarn的工作机制</h3><h4 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h4><ul>
<li>MR 程序提交到客户端所在的节点。</li>
<li>YarnRunner 向 ResourceManager 申请一个 Application。</li>
<li>RM 将该应用程序的资源路径返回给 YarnRunner。</li>
<li>该程序将运行所需资源提交到 HDFS 上。</li>
<li>程序资源提交完毕后，申请运行 mrAppMaster。</li>
<li>RM 将用户的请求初始化成一个 Task。</li>
<li>其中一个 NodeManager 领取到 Task 任务。</li>
<li>该 NodeManager 创建容器 Container，并产生 MRAppmaster。</li>
<li>Container 从 HDFS 上拷贝资源到本地。 </li>
<li>MRAppmaster 向 RM 申请运行 MapTask 资源。 </li>
<li>RM 将运行 MapTask 任务分配给另外两个 NodeManager，另两个 NodeManager 分 别领取任务并创建容器。</li>
<li>MR 向两个接收到任务的 NodeManager 发送程序启动脚本，这两个 NodeManager 分别启动 MapTask，MapTask 对数据分区排序。 </li>
<li>MrAppMaster 等待所有 MapTask 运行完毕后，向 RM 申请容器，运行 ReduceTask。 </li>
<li>ReduceTask 向 MapTask 获取相应分区的数据。</li>
<li>程序运行完毕后，MR 会向 RM 申请注销自己。</li>
</ul>
<h4 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h4><p><img src="/Hadoop%E6%90%AD%E5%BB%BA%E8%B0%83%E4%BC%98%E7%AC%94%E8%AE%B0/2022-01-16_16-03.png" alt="2022-01-16_16-03"></p>
<h3 id="Yarn核心参数配置"><a href="#Yarn核心参数配置" class="headerlink" title="Yarn核心参数配置"></a>Yarn核心参数配置</h3><blockquote>
<p>根据服务器的具体情况进行添加yarn-site.xml的配置</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 选择调度器，默认容量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>The class to use as the resource scheduler.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- ResourceManager处理调度器请求的线程数量,默认50；如果提交的任务数大于50，可以增加该值，但是不能超过3台 * 4线程 = 12线程（去除其他应用程序实际不能超过8） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>Number of threads to handle scheduler interface.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.client.thread-count<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否让yarn自动检测硬件进行配置，默认是false，如果该节点有很多其他应用程序，建议手动配置。如果该节点没有其他应用程序，可以采用自动 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>Enable auto-detection of node capabilities such as memory and CPU.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.detect-hardware-capabilities<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将虚拟核数当作CPU核数，默认是false，采用物理CPU核数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>Flag to determine if logical processors(such as</span><br><span class="line">     hyperthreads) should be counted as cores. Only applicable on Linux</span><br><span class="line">     when yarn.nodemanager.resource.cpu-vcores is set to -1 and</span><br><span class="line">     yarn.nodemanager.resource.detect-hardware-capabilities is true.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.count-logical-processors-as-cores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 虚拟核数和物理核数乘数，默认是1.0 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>Multiplier to determine how to convert phyiscal cores to</span><br><span class="line">     vcores. This value is used if yarn.nodemanager.resource.cpu-vcores</span><br><span class="line">     is set to -1(which implies auto-calculate vcores) and</span><br><span class="line">     yarn.nodemanager.resource.detect-hardware-capabilities is set to true. The number of vcores will be calculated as number of CPUs * multiplier.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.pcores-vcores-multiplier<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- NodeManager使用内存数，默认8G，修改为4G内存 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>Amount of physical memory, in MB, that can be allocated </span><br><span class="line">     for containers. If set to -1 and</span><br><span class="line">     yarn.nodemanager.resource.detect-hardware-capabilities is true, it is</span><br><span class="line">     automatically calculated(in case of Windows and Linux).</span><br><span class="line">     In other cases, the default is 8192MB.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- nodemanager的CPU核数，不按照硬件环境自动设定时默认是8个，修改为4个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>Number of vcores that can be allocated</span><br><span class="line">     for containers. This is used by the RM scheduler when allocating</span><br><span class="line">     resources for containers. This is not used to limit the number of</span><br><span class="line">     CPUs used by YARN containers. If it is set to -1 and</span><br><span class="line">     yarn.nodemanager.resource.detect-hardware-capabilities is true, it is</span><br><span class="line">     automatically determined from the hardware in case of Windows and Linux.</span><br><span class="line">     In other cases, number of vcores is 8 by default.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 容器最小内存，默认1G --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">         The minimum allocation for every container request at the RM in MBs. Memory requests lower than this will be set to the value of this property. Additionally, a node manager that is configured to have less memory than this value will be shut down by the resource manager.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 容器最大内存，默认8G，修改为2G --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">         The maximum allocation for every container request at the RM in MBs. Memory requests higher than this will throw an InvalidResourceRequestException.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 容器最小CPU核数，默认1个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">         The minimum allocation for every container request at the RM in terms of virtual CPU cores. Requests lower than this will be set to the value of this property. Additionally, a node manager that is configured to have fewer virtual cores than this value will be shut down by the resource manager.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 容器最大CPU核数，默认4个，修改为2个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">         The maximum allocation for every container request at the RM in terms of virtual CPU cores. Requests higher than this will throw an InvalidResourceRequestException.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 虚拟内存检查，默认打开，修改为关闭 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">         Whether virtual memory limits will be enforced for containers.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 虚拟内存和物理内存设置比例,默认2.1 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">         Ratio between virtual memory to physical memory when setting memory limits for containers. Container allocations are expressed in terms of physical memory, and virtual memory usage is allowed to exceed this allocation by this ratio.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>2.1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启优先级，有5个等级 （）--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.cluster.max-application-priority<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="Yarn的调度器"><a href="#Yarn的调度器" class="headerlink" title="Yarn的调度器"></a>Yarn的调度器</h3><blockquote>
<p>在实际开发中一般不使用FIFO调度器。</p>
<p>容量调度器：中小型企业使用，对程序并发度要求不高。</p>
<p>公平调度器：中大型企业使用，对程序并发度要求较高。</p>
</blockquote>
<h4 id="容量调度器"><a href="#容量调度器" class="headerlink" title="容量调度器"></a>容量调度器</h4><h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><ol>
<li>多队列：每个队列可配置一定的资源量，每个队列采用FIFO调度策略。</li>
<li>容量保证：管理员可为每个队列设置资源最低保证和资源使用上限 </li>
<li>灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用 程序提交，则其他队列借调的资源会归还给该队列。 </li>
<li>多租户： 支持多用户共享集群和多应用程序同时运行。 为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源量进行限定</li>
</ol>
<h5 id="资源分配算法"><a href="#资源分配算法" class="headerlink" title="资源分配算法"></a>资源分配算法</h5><ol>
<li><p>队列资源分配</p>
<p>使用深度优先算法，优先 选择资源占用率最低的队列分配资源。</p>
</li>
<li><p>作业资源分配</p>
<p>默认按照提交作业的优先级和提交时间 顺序分配资源。(FIFO)</p>
</li>
<li><p>容器资源分配</p>
<p>按照容器的优先级分配资源； 如果优先级相同，按照数据本地性原则：</p>
<ol>
<li>任务和数据在同一节点</li>
<li>任务和数据在同一机架 </li>
<li>任务和数据不在同一节点也不在同一机架</li>
</ol>
</li>
</ol>
<h5 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h5><h6 id="capacity-scheduler-xml"><a href="#capacity-scheduler-xml" class="headerlink" title="capacity-scheduler.xml"></a>capacity-scheduler.xml</h6><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--（1）修改默认属性配置：--&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定多队列，增加hive队列 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.queues<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>default,hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      The queues at the this level (root is the root queue).</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 降低default队列资源额定容量为40%，默认100% --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>40<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 降低default队列资源最大容量为60%，默认100% --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.maximum-capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--（2）为新加队列添加必要属性：--&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定hive队列的资源额定容量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 用户最多可以使用队列多少资源，1表示 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.user-limit-factor<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hive队列的资源最大容量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.maximum-capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>80<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 启动hive队列 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.state<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>RUNNING<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 哪些用户有权向队列提交作业 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.acl_submit_applications<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 哪些用户有权操作队列，管理员权限（查看/杀死） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.acl_administer_queue<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 哪些用户有权配置提交任务优先级 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.acl_application_max_priority<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 任务的超时时间设置：yarn application -appId appId -updateLifetime Timeout</span></span><br><span class="line"><span class="comment">参考资料：https://blog.cloudera.com/enforcing-application-lifetime-slas-yarn/ --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 如果application指定了超时时间，则提交到该队列的application能够指定的最大超时时间不能超过该值。 </span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.maximum-application-lifetime<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 如果application没指定超时时间，则用default-application-lifetime作为默认值 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.default-application-lifetime<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="公平调度器"><a href="#公平调度器" class="headerlink" title="公平调度器"></a>公平调度器</h4><blockquote>
<p>在Apache的hadoop中默认的是容量调度器，如果需要修改为公平调度器，需要修改yarn-site.xml文件指定容器类型。</p>
</blockquote>
<h5 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h5><ol>
<li>多队列：每个队列可配置一定的资源量，每个队列采用FIFO调度策略。</li>
<li>容量保证：管理员可为每个队列设置资源最低保证和资源使用上限 </li>
<li>灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用 程序提交，则其他队列借调的资源会归还给该队列。 </li>
<li>多租户： 支持多用户共享集群和多应用程序同时运行。 为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源量进行限定</li>
</ol>
<h5 id="资源分配算法-1"><a href="#资源分配算法-1" class="headerlink" title="资源分配算法"></a>资源分配算法</h5><blockquote>
<p>缺额：作业获取资源的过程并不是瞬间得到，而是在一段时间内不断获取。某个任务理想中得到的资源与现有的资源的差值就是缺额</p>
<p>公平调度器设计目标是：在时间尺度上，所有作业获得公平的资源。某一 时刻一个作业应获资源和实际获取资源的差距叫“缺额” ，调度器会优先为缺额大的作业分配资。(Fair)</p>
</blockquote>
<p> Fair 策略（默认）是一种基于最大最小公平算法实现的资源多路复用方式，默认情况下，每个队列内部采用该方式分配资 源。这意味着，如果一个队列中有两个应用程序同时运行，则每个应用程序可得到1&#x2F;2的资源；如果三个应用程序同时运行，则 每个应用程序可得到1&#x2F;3的资源。 分别计算比较对象的（实际最小资源份额、是 否饥饿、资源分配比、资源使用权重比） 具体资源分配流程和容量调度器一致；</p>
<ol>
<li>队列资源分配</li>
<li>作业资源分配</li>
<li>容器资源分配</li>
</ol>
<p>以上三步，每一步都是按照公平策略分配资源</p>
<p>➢ 实际最小资源份额：mindshare &#x3D; Min（资源需求量，配置的最小资源） </p>
<p>➢ 是否饥饿：isNeedy &#x3D; 资源使用量 &lt; mindshare（实际最小资源份额） </p>
<p>➢ 资源分配比：minShareRatio &#x3D; 资源使用量 &#x2F; Max（mindshare, 1） </p>
<p>➢ 资源使用权重比：useToWeightRatio &#x3D; 资源使用量 &#x2F; 权重</p>
<h5 id="配置文件-1"><a href="#配置文件-1" class="headerlink" title="配置文件"></a>配置文件</h5><h6 id="yarn-site-xml-1"><a href="#yarn-site-xml-1" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h6><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairS</span><br><span class="line">cheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">description</span>&gt;</span>配置使用公平调度器<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.fair.allocation.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.3.1/etc/hadoop/fair-scheduler.xml<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">description</span>&gt;</span>指明公平调度器队列分配配置文件<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.fair.preemption<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">description</span>&gt;</span>禁止队列间资源抢占<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h6 id="fair-scheduler-xml"><a href="#fair-scheduler-xml" class="headerlink" title="fair-scheduler.xml"></a>fair-scheduler.xml</h6><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">allocations</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 单个队列中 Application Master 占用资源的最大比例,取值 0-1 ，企业一般配置 0.1 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">queueMaxAMShareDefault</span>&gt;</span>0.5<span class="tag">&lt;/<span class="name">queueMaxAMShareDefault</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 单个队列最大资源的默认值 test luo default --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">queueMaxResourcesDefault</span>&gt;</span>4096mb,4vcores<span class="tag">&lt;/<span class="name">queueMaxResourcesDefault</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 增加一个队列 test --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">&quot;test&quot;</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列最小资源 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">minResources</span>&gt;</span>2048mb,2vcores<span class="tag">&lt;/<span class="name">minResources</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列最大资源 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">maxResources</span>&gt;</span>4096mb,4vcores<span class="tag">&lt;/<span class="name">maxResources</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列中最多同时运行的应用数，默认 50，根据线程数配置 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">maxRunningApps</span>&gt;</span>4<span class="tag">&lt;/<span class="name">maxRunningApps</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列中 Application Master 占用资源的最大比例 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">maxAMShare</span>&gt;</span>0.5<span class="tag">&lt;/<span class="name">maxAMShare</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 该队列资源权重,默认值为 1.0 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列内部的资源分配策略 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 增加一个队列 luo --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">&quot;luo&quot;</span> <span class="attr">type</span>=<span class="string">&quot;parent&quot;</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列最小资源 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">minResources</span>&gt;</span>2048mb,2vcores<span class="tag">&lt;/<span class="name">minResources</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列最大资源 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">maxResources</span>&gt;</span>4096mb,4vcores<span class="tag">&lt;/<span class="name">maxResources</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列中最多同时运行的应用数，默认 50，根据线程数配置 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">maxRunningApps</span>&gt;</span>4<span class="tag">&lt;/<span class="name">maxRunningApps</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列中 Application Master 占用资源的最大比例 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">maxAMShare</span>&gt;</span>0.5<span class="tag">&lt;/<span class="name">maxAMShare</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 该队列资源权重,默认值为 1.0 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 队列内部的资源分配策略 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 任务队列分配策略,可配置多层规则,从第一个规则开始匹配,直到匹配成功 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">queuePlacementPolicy</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 提交任务时指定队列,如未指定提交队列,则继续匹配下一个规则; false 表示：如果指</span></span><br><span class="line"><span class="comment">        定队列不存在,不允许自动创建--&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;specified&quot;</span> <span class="attr">create</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 提交到 root.group.username 队列,若 root.group 不存在,不允许自动创建；若</span></span><br><span class="line"><span class="comment">        root.group.user 不存在,允许自动创建 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;nestedUserQueue&quot;</span> <span class="attr">create</span>=<span class="string">&quot;true&quot;</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;primaryGroup&quot;</span> <span class="attr">create</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 最后一个规则必须为 reject 或者 default。Reject 表示拒绝创建提交失败，</span></span><br><span class="line"><span class="comment">        default 表示把任务提交到 default 队列 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;reject&quot;</span> /&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">queuePlacementPolicy</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">allocations</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="Tool接口的编写"><a href="#Tool接口的编写" class="headerlink" title="Tool接口的编写"></a>Tool接口的编写</h3><blockquote>
<p>为了方便对程序的使用编写接口</p>
<p>以WordCount为例</p>
</blockquote>
<h4 id="WordCount"><a href="#WordCount" class="headerlink" title="WordCount"></a>WordCount</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.luo.TOO接口案例;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span> <span class="keyword">implements</span> <span class="title class_">Tool</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Configuration conf;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">run</span><span class="params">(String[] strings)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(WordCountDriver.class);</span><br><span class="line">        job.setMapperClass(WCMapper.class);</span><br><span class="line">        job.setReducerClass(WCReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(strings[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(strings[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setConf</span><span class="params">(Configuration configuration)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.conf = configuration;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Configuration <span class="title function_">getConf</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> conf;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">WCMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outK</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">            <span class="keyword">for</span> (String s : line.split(<span class="string">&quot; &quot;</span>)) &#123;</span><br><span class="line">                outK.set(s);</span><br><span class="line">                context.write(outK, outV);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">WCReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">                sum += value.get();</span><br><span class="line">            &#125;</span><br><span class="line">            outV.set(sum);</span><br><span class="line">            context.write(key, outV);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="WordCountDriver"><a href="#WordCountDriver" class="headerlink" title="WordCountDriver"></a>WordCountDriver</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.luo.TOO接口案例;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Tool tool;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">switch</span> (args[<span class="number">0</span>])&#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;wordcount&quot;</span>:</span><br><span class="line">                tool = <span class="keyword">new</span> <span class="title class_">WordCount</span>();</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                System.out.println(<span class="string">&quot;非法接口：&quot;</span> + args[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">run</span> <span class="operator">=</span> ToolRunner.run(conf, tool, Arrays.copyOfRange(args, args.length - <span class="number">2</span>, args.length));</span><br><span class="line">        System.exit(run);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="生产调优"><a href="#生产调优" class="headerlink" title="生产调优"></a>生产调优</h2><h3 id="HDFS—核心参数"><a href="#HDFS—核心参数" class="headerlink" title="HDFS—核心参数"></a>HDFS—核心参数</h3><h4 id="NameNode、DataNode内存生产配置"><a href="#NameNode、DataNode内存生产配置" class="headerlink" title="NameNode、DataNode内存生产配置"></a>NameNode、DataNode内存生产配置</h4><h5 id="NameNode内存计算"><a href="#NameNode内存计算" class="headerlink" title="NameNode内存计算"></a>NameNode内存计算</h5><p>每个文件块大概占用 150byte。一台服务器 128G 内存为例，能存储128 * 1024 * 1024 * 1024 &#x2F; 150Byte ≈ 9.1 亿</p>
<h5 id="配置-NameNode、DataNode内存"><a href="#配置-NameNode、DataNode内存" class="headerlink" title="配置 NameNode、DataNode内存"></a>配置 NameNode、DataNode内存</h5><blockquote>
<p>在Hadoop3.x 系列中默认NameNode是根据服务器动态分配的。</p>
<p>配置文件：hadoop-env.sh</p>
</blockquote>
<p>配置策略：</p>
<ol>
<li>NameNode：最小值为1G，每增加1000000个block，增加1G内存</li>
<li>DataNode：在一个DataNode上的副本总数低于4000000，调为4G。超过4000000，每增加1000000，增加1G</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HDFS_NAMENODE_OPTS=&quot;-Dhadoop.security.logger=INFO,RFAS -Xmx1024m&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">当前机器为学习机器，所以调为1G。</span></span><br><span class="line">export HDFS_DATANODE_OPTS=&quot;-Dhadoop.security.logger=ERROR,RFAS -Xmx1024m&quot;</span><br></pre></td></tr></table></figure>

<h4 id="NameNode-心跳并发配置"><a href="#NameNode-心跳并发配置" class="headerlink" title="NameNode 心跳并发配置"></a>NameNode 心跳并发配置</h4><blockquote>
<p>NameNode 有一个工作线程池，用来处理不同 DataNode 的并发心跳以及客户端并发 的元数据操作。 对于大集群或者有大量客户端的集群来说，通常需要增大该参数。默认值是 10。</p>
<p>配置文件：hdfs-site.xml</p>
</blockquote>
<p>企业经验：dfs.namenode.handler.count&#x3D;20 × log以e为底的集群数量，比如集群规模（DataNode 台数）为 3 台时，此参数设置为 21。<br>使用Python计算：print(int(20*math.log(3)))<br>$$<br>dfs.namenode.handler.count&#x3D;20 × log_{e}^{n}<br>$$</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.handler.count<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>21<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="开启回收站配置"><a href="#开启回收站配置" class="headerlink" title="开启回收站配置"></a>开启回收站配置</h4><blockquote>
<p>开启回收站功能，可以将删除的文件在不超时的情况下，恢复原数据，起到防止误删除、 备份等作用。</p>
<p>单位为分钟。0 表示禁用回收站；其他值表示设置文件的存活时间。</p>
<p>配置文件 ：core-site.xml</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="HDFS—多目录"><a href="#HDFS—多目录" class="headerlink" title="HDFS—多目录"></a>HDFS—多目录</h3><h4 id="NameNode-多目录配置"><a href="#NameNode-多目录配置" class="headerlink" title="NameNode 多目录配置"></a>NameNode 多目录配置</h4><blockquote>
<p>NameNode 的本地目录可以配置成多个，且每个目录存放内容相同，增加了可靠性。</p>
<p>在 hdfs-site.xml 文件中添加如下内容</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/dfs/name1,file://$&#123;hadoop.tmp.dir&#125;/dfs/name2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>重启集群</p>
<p>停止集群，删除三台节点的 data 和 logs 中所有数据。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ rm -rf data/ logs/</span><br><span class="line">[luo@hadoop103 hadoop-3.3.1]$ rm -rf data/ logs/</span><br><span class="line">[luo@hadoop104 hadoop-3.3.1]$ rm -rf data/ logs/</span><br></pre></td></tr></table></figure>

<blockquote>
<p>格式化集群并启动。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ bin/hdfs namenode -format</span><br><span class="line">[luo@hadoop102 hadoop-3.3.1]$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>

<h4 id="DataNode-多目录配置"><a href="#DataNode-多目录配置" class="headerlink" title="DataNode 多目录配置"></a>DataNode 多目录配置</h4><blockquote>
<p>DataNode 可以配置成多个目录，每个目录存储的数据不一样（数据不是副本）</p>
<p>在 hdfs-site.xml 文件中添加如下内容</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/dfs/data1,file://$&#123;hadoop.tmp.dir&#125;/dfs/data2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="集群数据均衡之磁盘间数据均衡"><a href="#集群数据均衡之磁盘间数据均衡" class="headerlink" title="集群数据均衡之磁盘间数据均衡"></a>集群数据均衡之磁盘间数据均衡</h4><blockquote>
<p>生产环境，由于硬盘空间不足，往往需要增加一块硬盘。刚加载的硬盘没有数据时，可 以执行磁盘数据均衡命令。（Hadoop3.x 新特性）</p>
</blockquote>
<ol>
<li>生成均衡计划（我们只有一块磁盘，不会生成计划）</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs diskbalancer -plan hadoop103 </span><br></pre></td></tr></table></figure>

<ol start="2">
<li>执行均衡计划</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs diskbalancer -execute hadoop103.plan.json </span><br></pre></td></tr></table></figure>

<ol start="3">
<li>查看当前均衡任务的执行情况</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs diskbalancer -query hadoop103 </span><br></pre></td></tr></table></figure>

<ol start="4">
<li>取消均衡任务</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs diskbalancer -cancel hadoop103.plan.json</span><br></pre></td></tr></table></figure>

<h3 id="HDFS—集群扩容及缩容"><a href="#HDFS—集群扩容及缩容" class="headerlink" title="HDFS—集群扩容及缩容"></a>HDFS—集群扩容及缩容</h3><h4 id="添加黑白名单"><a href="#添加黑白名单" class="headerlink" title="添加黑白名单"></a>添加黑白名单</h4><blockquote>
<p>白名单：表示在白名单的主机 IP 地址可以用来存储数据。 </p>
<p>企业中：配置白名单，可以尽量防止黑客恶意访问攻击。</p>
<p>黑名单：表示在黑名单的主机 IP 地址不可以用来存储数据。</p>
<p> 企业中：配置黑名单，用来退役服务器。</p>
<p>配置文件： hdfs-site.xml</p>
</blockquote>
<ol>
<li><p>创建黑白名单</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop]$ vim whitelist</span><br><span class="line">[luo@hadoop102 hadoop]$ vim blicklist</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 hdfs-site.xml 配置文件中增加 dfs.hosts 配置参数</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 白名单 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.3.1/etc/hadoop/whitelist<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 黑名单 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts.exclude<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.3.1/etc/hadoop/blacklist<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>分发配置文件 whitelist，hdfs-site.xm</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop104 hadoop]$ xsync hdfs-site.xml whitelist</span><br></pre></td></tr></table></figure>
</li>
<li><p>第一次添加白名单必须重启集群，不是第一次，只需要刷新 NameNode 节点即可</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ myhadoop.sh stop</span><br><span class="line">[luo@hadoop102 hadoop-3.3.1]$ myhadoop.sh start</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">刷新 NameNode命令</span></span><br><span class="line">[luo@hadoop102 hadoop-3.3.1]$ hdfs dfsadmin -refreshNodesRefresh nodes successful</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="服役新服务器"><a href="#服役新服务器" class="headerlink" title="服役新服务器"></a>服役新服务器</h4><blockquote>
<p>随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据 的需求，需要在原有集群基础上动态添加新的数据节点。</p>
</blockquote>
<ol>
<li><p>配置 hadoop102 和 hadoop103 到 hadoop105 的 ssh 无密登录(NameNode和Yarn所在节点）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">102</span></span><br><span class="line">[luo@hadoop102 .ssh]$ ssh-copy-id hadoop105</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">103</span></span><br><span class="line">[luo@hadoop103 .ssh]$ ssh-copy-id hadoop105</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加workers</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br><span class="line">hadoop105</span><br></pre></td></tr></table></figure>
</li>
<li><p>分发 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">只分发配置文件</span></span><br><span class="line">[luo@hadoop102 hadoop]$ xsync hadoop</span><br></pre></td></tr></table></figure>
</li>
<li><p>直接启动 新节点，即可关联到集群</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop105 hadoop-3.3.1]$ hdfs --daemon start datanode</span><br><span class="line">[luo@hadoop105 hadoop-3.3.1]$ yarn --daemon start nodemanager</span><br></pre></td></tr></table></figure>
</li>
<li><p>刷新 NameNode</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ hdfs dfsadmin -refreshNodesRefresh nodes successful</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="服务器间数据均衡"><a href="#服务器间数据均衡" class="headerlink" title="服务器间数据均衡"></a>服务器间数据均衡</h4><blockquote>
<ol>
<li>在企业开发中，如果经常在 hadoop102 和 hadoop104 上提交任务，且副本数为 2，由于 数据本地性原则，就会导致 hadoop102 和 hadoop104 数据过多，hadoop103 存储的数据量小。</li>
<li>另一种情况，就是新服役的服务器数据量比较少，需要执行集群均衡命令。</li>
<li>&#x3D;&#x3D;注意：由于 HDFS 需要启动单独的 Rebalance Server 来执行 Rebalance 操作，所以尽量 不要在 NameNode 上执行 start-balancer.sh，而是找一台比较空闲的机器。&#x3D;&#x3D;</li>
</ol>
</blockquote>
<ol>
<li><p>开启数据均衡命令</p>
<blockquote>
<p>对于参数 10，代表的是集群中各个节点的磁盘空间利用率相差不超过 10%，可根据实 际情况进行调整。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ sbin/start-balancer.sh -threshold 10</span><br></pre></td></tr></table></figure>
</li>
<li><p>停止数据均衡命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ sbin/stop-balancer.sh</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="黑名单退役服务器"><a href="#黑名单退役服务器" class="headerlink" title="黑名单退役服务器"></a>黑名单退役服务器</h4><ol>
<li><p>编辑&#x2F;opt&#x2F;module&#x2F;hadoop-3.3.1&#x2F;etc&#x2F;hadoop 目录下的 blacklist 文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加加入黑名单的服务器</span></span><br><span class="line">hadoop105</span><br></pre></td></tr></table></figure>
</li>
<li><p>分发配置文件 blacklist</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xsync hdfs-site.xml </span><br></pre></td></tr></table></figure>
</li>
<li><p>刷新 NameNode 节点</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs dfsadmin -refreshNodesRefresh nodes successful</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="HDFS—存储优化"><a href="#HDFS—存储优化" class="headerlink" title="HDFS—存储优化"></a>HDFS—存储优化</h3><h4 id="纠删码"><a href="#纠删码" class="headerlink" title="纠删码"></a>纠删码</h4><blockquote>
<p>HDFS 默认情况下，一个文件有 3 个副本，这样提高了数据的可靠性，但也带来了 2 倍 的冗余开销。Hadoop3.x 引入了纠删码，采用计算的方式，可以节省约 50％左右的存储空间。</p>
</blockquote>
<ol>
<li><p>纠删码操作相关的命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ hdfs ec</span><br><span class="line">Usage: bin/hdfs ec [COMMAND]</span><br><span class="line"> [-listPolicies]</span><br><span class="line"> [-addPolicies -policyFile &lt;file&gt;]</span><br><span class="line"> [-getPolicy -path &lt;path&gt;]</span><br><span class="line"> [-removePolicy -policy &lt;policy&gt;]</span><br><span class="line"> [-setPolicy -path &lt;path&gt; [-policy &lt;policy&gt;] [-replicate]]</span><br><span class="line"> [-unsetPolicy -path &lt;path&gt;]</span><br><span class="line"> [-listCodecs]</span><br><span class="line"> [-enablePolicy -policy &lt;policy&gt;]</span><br><span class="line"> [-disablePolicy -policy &lt;policy&gt;]</span><br><span class="line"> [-help &lt;command-name&gt;].</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看当前支持的纠删码策略</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1] hdfs ec -listPolicies</span><br><span class="line">Erasure Coding Policies:</span><br><span class="line">ErasureCodingPolicy=[Name=RS-10-4-1024k, Schema=[ECSchema=[Codec=rs, </span><br><span class="line">numDataUnits=10, numParityUnits=4]], CellSize=1048576, Id=5], </span><br><span class="line">State=DISABLED</span><br><span class="line">ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, </span><br><span class="line">numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2], </span><br><span class="line">State=DISABLED</span><br><span class="line">ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, </span><br><span class="line">numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1], </span><br><span class="line">State=ENABLED</span><br><span class="line">ErasureCodingPolicy=[Name=RS-LEGACY-6-3-1024k, </span><br><span class="line">Schema=[ECSchema=[Codec=rs-legacy, numDataUnits=6, numParityUnits=3]], </span><br><span class="line">CellSize=1048576, Id=3], State=DISABLED</span><br><span class="line">ErasureCodingPolicy=[Name=XOR-2-1-1024k, Schema=[ECSchema=[Codec=xor, </span><br><span class="line">numDataUnits=2, numParityUnits=1]], CellSize=1048576, Id=4], </span><br><span class="line">State=DISABLED</span><br></pre></td></tr></table></figure>
</li>
<li><p>纠删码策略解释:</p>
<ol>
<li>RS-3-2-1024k：使用 RS 编码，每 3 个数据单元，生成 2 个校验单元，共 5 个单元，也 就是说：这 5 个单元中，只要有任意的 3 个单元存在（不管是数据单元还是校验单元，只要总数&#x3D;3），就可以得到原始数据。每个单元的大小是 1024k&#x3D;1024*1024&#x3D;1048576。</li>
<li>RS-10-4-1024k：使用 RS 编码，每 10 个数据单元（cell），生成 4 个校验单元，共 14 个单元，也就是说：这 14 个单元中，只要有任意的 10 个单元存在（不管是数据单元还是校 验单元，只要总数&#x3D;10），就可以得到原始数据。每个单元的大小是 1024k&#x3D;1024*1024&#x3D;1048576。</li>
<li>RS-6-3-1024k：使用 RS 编码，每 6 个数据单元，生成 3 个校验单元，共 9 个单元，也 就是说：这 9 个单元中，只要有任意的 6 个单元存在（不管是数据单元还是校验单元，只要 总数&#x3D;6），就可以得到原始数据。每个单元的大小是 1024k&#x3D;1024*1024&#x3D;1048576。</li>
<li>RS-LEGACY-6-3-1024k：策略和上面的 RS-6-3-1024k 一样，只是编码的算法用的是 rs-legacy</li>
<li>XOR-2-1-1024k：使用 XOR 编码（速度比 RS 编码快），每 2 个数据单元，生成 1 个校 验单元，共 3 个单元，也就是说：这 3 个单元中，只要有任意的 2 个单元存在（不管是数据 单元还是校验单元，只要总数&#x3D; 2），就可以得到原始数据。每个单元的大小是 1024k&#x3D;1024*1024&#x3D;1048576。</li>
</ol>
</li>
<li><p>具体步骤</p>
<ol>
<li><p>开启对 RS-3-2-1024k 策略的支持</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ hdfs ec -enablePolicy -policy RS-3-2-1024k</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 HDFS 创建目录，并设置 RS-3-2-1024k 策略</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ hdfs dfs -mkdir /input</span><br><span class="line">[luo@hadoop202 hadoop-3.3.1]$ hdfs ec -setPolicy -path /input -policy RS-3-2-1024k</span><br></pre></td></tr></table></figure>
</li>
<li><p>并查看文件编码后的存储情况</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[luo@hadoop102 hadoop-3.3.1]$ hdfs dfs -put web.log /input</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h4 id="异构存储（冷热数据分离）"><a href="#异构存储（冷热数据分离）" class="headerlink" title="异构存储（冷热数据分离）"></a>异构存储（冷热数据分离）</h4><blockquote>
<p>异构存储主要解决，不同的数据，存储在不同类型的硬盘中，达到最佳性能的问题。</p>
</blockquote>
<h3 id="HDFS—故障排除"><a href="#HDFS—故障排除" class="headerlink" title="HDFS—故障排除"></a>HDFS—故障排除</h3><h4 id="NameNode-故障处理"><a href="#NameNode-故障处理" class="headerlink" title="NameNode 故障处理"></a>NameNode 故障处理</h4><blockquote>
<p>NameNode 进程挂了并且存储的数据也丢失了，如何恢复 NameNode</p>
</blockquote>
<ol>
<li><p>拷贝 SecondaryNameNode 中数据到原 NameNode 存储数据目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 dfs]$ scp -r atguigu@hadoop104:/opt/module/hadoop-3.1.3/data/dfs/namesecondary/* ./name/</span><br></pre></td></tr></table></figure>
</li>
<li><p>重新启动 NameNode</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hdfs --daemon start namenode</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="集群安全模式-amp-磁盘修复"><a href="#集群安全模式-amp-磁盘修复" class="headerlink" title="集群安全模式&amp;磁盘修复"></a>集群安全模式&amp;磁盘修复</h4><ol>
<li><p>退出安全模式条件</p>
<ul>
<li>dfs.namenode.safemode.min.datanodes:最小可用 datanode 数量，默认 0 </li>
<li>dfs.namenode.safemode.threshold-pct:副本数达到最小要求的 block 占系统总 block 数的 百分比，默认 0.999f。（只允许丢一个块）</li>
<li>dfs.namenode.safemode.extension:稳定时间，默认值 30000 毫秒，即 30 秒</li>
</ul>
</li>
<li><p>基本语法</p>
<blockquote>
<p>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模 式。</p>
</blockquote>
<ul>
<li>bin&#x2F;hdfs dfsadmin -safemode get （功能描述：查看安全模式状态）</li>
<li>bin&#x2F;hdfs dfsadmin -safemode enter （功能描述：进入安全模式状态）</li>
<li>bin&#x2F;hdfs dfsadmin -safemode leave（功能描述：离开安全模式状态）</li>
<li>bin&#x2F;hdfs dfsadmin -safemode wait （功能描述：等待安全模式状态）：在等待安全模式下提交任务，任务会在集群离开安全模式后自动运行提交的任务</li>
</ul>
</li>
<li><p>磁盘修复</p>
<blockquote>
<p>文件块及其副本全部丢失，集群进入锁死状态</p>
</blockquote>
<p>离开安全模式</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 subdir0]$ hdfs dfsadmin -safemode get Safe mode is ON</span><br><span class="line">[atguigu@hadoop102 subdir0]$ hdfs dfsadmin -safemode leave Safe mode is OFF</span><br></pre></td></tr></table></figure>

<p>将元数据删除</p>
</li>
</ol>
<h4 id="小文件归档"><a href="#小文件归档" class="headerlink" title="小文件归档"></a>小文件归档</h4><blockquote>
<p>HDFS 存档文件或 HAR 文件，是一个更高效的文件存档工具，它将文件存入 HDFS 块， 在减少 NameNode 内存使用的同时，允许对文件进行透明的访问。具体说来，HDFS 存档文 件对内还是一个一个独立文件，对 NameNode 而言却是一个整体，减少了 NameNode 的内 存。</p>
</blockquote>
<ol>
<li><p>需要启动 YARN 进程</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ start-yarn.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>归档文件</p>
<blockquote>
<p>把&#x2F;input 目录里面的所有文件归档成一个叫 input.har 的归档文件，并把归档后文件存储 到&#x2F;output 路径下。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop archive -archiveName input.har -p /input /output</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看归档</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -ls /output/input.har</span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -ls har:///output/input.har</span><br></pre></td></tr></table></figure>
</li>
<li><p>解归档文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -cp har:///output/input.har/* /</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="HDFS—集群迁移"><a href="#HDFS—集群迁移" class="headerlink" title="HDFS—集群迁移"></a>HDFS—集群迁移</h3><h4 id="Apache-和-Apache-集群间数据拷贝"><a href="#Apache-和-Apache-集群间数据拷贝" class="headerlink" title="Apache 和 Apache 集群间数据拷贝"></a>Apache 和 Apache 集群间数据拷贝</h4><p>采用 distcp 命令实现两个 Hadoop 集群之间的递归数据复制</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ bin/hadoop distcp hdfs://hadoop102:8020/user/atguigu/hello.txt hdfs://hadoop105:8020/user/atguigu/hello.txt</span><br></pre></td></tr></table></figure>

<h4 id="Apache-和-CDH-集群间数据拷贝"><a href="#Apache-和-CDH-集群间数据拷贝" class="headerlink" title="Apache 和 CDH 集群间数据拷贝"></a>Apache 和 CDH 集群间数据拷贝</h4><blockquote>
<p>不常见</p>
</blockquote>
<h3 id="MapReduce-生产经验"><a href="#MapReduce-生产经验" class="headerlink" title="MapReduce 生产经验"></a>MapReduce 生产经验</h3><h4 id="MapReduce-跑的慢的原因"><a href="#MapReduce-跑的慢的原因" class="headerlink" title="MapReduce 跑的慢的原因"></a>MapReduce 跑的慢的原因</h4><blockquote>
<p>MapReduce 程序效率的瓶颈在于两点：</p>
</blockquote>
<ol>
<li><p>计算机性能</p>
<p>CPU、内存、磁盘、网络</p>
</li>
<li><p>I&#x2F;O 操作优化</p>
<ul>
<li>数据倾斜</li>
<li>Map 运行时间太长，导致 Reduce 等待过久</li>
<li>小文件过多</li>
</ul>
</li>
</ol>
<h4 id="MapReduce-常用调优参数"><a href="#MapReduce-常用调优参数" class="headerlink" title="MapReduce 常用调优参数"></a>MapReduce 常用调优参数</h4><h5 id="Map——-gt-Shuffle"><a href="#Map——-gt-Shuffle" class="headerlink" title="Map——&gt;Shuffle"></a>Map——&gt;Shuffle</h5><p><img src="/Hadoop%E6%90%AD%E5%BB%BA%E8%B0%83%E4%BC%98%E7%AC%94%E8%AE%B0/2022-01-24_15-36.png"></p>
<h6 id="自定义分区，减少数据倾斜"><a href="#自定义分区，减少数据倾斜" class="headerlink" title="自定义分区，减少数据倾斜"></a>自定义分区，减少数据倾斜</h6><p>   定义类，继承Partitioner接口，重写getPartition方法</p>
<h6 id="减少溢写的次数"><a href="#减少溢写的次数" class="headerlink" title="减少溢写的次数"></a>减少溢写的次数</h6><ul>
<li>mapreduce.task.io.sort.mb Shuffle的环形缓冲区大小，默认100m，可以提高到200m </li>
<li>mapreduce.map.sort.spill.percent 环形缓冲区溢出的阈值，默认80% ，可以提高的90%</li>
</ul>
<h6 id="增加每次Merge合并次数"><a href="#增加每次Merge合并次数" class="headerlink" title="增加每次Merge合并次数"></a>增加每次Merge合并次数</h6><p>   mapreduce.task.io.sort.factor默认10，可以提高到20</p>
<h6 id="采用Combiner"><a href="#采用Combiner" class="headerlink" title="采用Combiner"></a>采用Combiner</h6><blockquote>
<p>在不影响业务结果的前提条件下可以提前</p>
</blockquote>
<p>   job.setCombinerClass(xxxReducer.class)</p>
<h6 id="采用Snappy或者LZO压缩"><a href="#采用Snappy或者LZO压缩" class="headerlink" title="采用Snappy或者LZO压缩"></a>采用Snappy或者LZO压缩</h6><blockquote>
<p>减少磁盘IO</p>
</blockquote>
<ul>
<li>conf.setBoolean(“mapreduce.map.output.compress”, true); </li>
<li>conf.setClass(“mapreduce.map.output.compress.codec”,  SnappyCodec.class,CompressionCodec.class);</li>
</ul>
<h6 id="提高MapTask内存上限"><a href="#提高MapTask内存上限" class="headerlink" title="提高MapTask内存上限"></a>提高MapTask内存上限</h6><p>   mapreduce.map.memory.mb 默认MapTask内存上限1024MB。 可以根据128m数据对应1G内存原则提高该内存。</p>
<h6 id="控制MapTask堆内存大小"><a href="#控制MapTask堆内存大小" class="headerlink" title="控制MapTask堆内存大小"></a>控制MapTask堆内存大小</h6><p>   mapreduce.map.java.opts：控制MapTask堆内存大小。（如果内存不够， 报：java.lang.OutOfMemoryError）</p>
<h6 id="增加MapTask的CPU核数"><a href="#增加MapTask的CPU核数" class="headerlink" title="增加MapTask的CPU核数"></a>增加MapTask的CPU核数</h6><p>   mapreduce.map.cpu.vcores 默认MapTask的CPU核数1。计算密集型任 务可以增加CPU核数</p>
<h6 id="异常重试"><a href="#异常重试" class="headerlink" title="异常重试"></a>异常重试</h6><p>   mapreduce.map.maxattempts每个Map Task最大重试次数，一旦重试 次数超过该值，则认为Map Task运行失败，默认值：4。根据机器 性能适当提高。</p>
<h5 id="Shuffle——-gt-Reduce"><a href="#Shuffle——-gt-Reduce" class="headerlink" title="Shuffle——&gt;Reduce"></a>Shuffle——&gt;Reduce</h5><p><img src="/Hadoop%E6%90%AD%E5%BB%BA%E8%B0%83%E4%BC%98%E7%AC%94%E8%AE%B0/2022-01-24_17-26.png"></p>
<ul>
<li>mapreduce.reduce.shuffle.parallelcopies每个Reduce去Map 中拉取数据的并行数，默认值是5。可以提高到10。</li>
<li>mapreduce.reduce.shuffle.input.buffer.percent Buffer大小占Reduce可用内存的比例，默认值0.7。可以提高到0.8</li>
<li>mapreduce.reduce.shuffle.merge.percent Buffer中的数据达到多少比例 开始写入磁盘，默认值0.66。可以提高到0.75</li>
<li>mapreduce.reduce.memory.mb 默认ReduceTask内存上限1024MB， 根据128m数据对应1G内存原则，适当提高内存到4-6G</li>
<li>mapreduce.reduce.java.opts：控制ReduceTask堆内存大小。（如果内 存不够，报：java.lang.OutOfMemoryError）</li>
<li>mapreduce.reduce.cpu.vcores默认ReduceTask的CPU核数1个。可 以提高到2-4个</li>
<li>mapreduce.reduce.maxattempts每个Reduce Task最大重试次数， 一旦重试次数超过该值，则认为Map Task运行失败，默认值：4。</li>
<li>mapreduce.job.reduce.slowstart.completedmaps当MapTask完成的比 例达到该值后才会为ReduceTask申请资源。默认是0.05。</li>
<li>mapreduce.task.timeout如果一个Task在一定时间内没有任何进入， 即不会读取新的数据，也没有输出数据，则认为该Task处于Block状态， 可能是卡住了，也许永远会卡住，为了防止因为用户程序永远Block住 不退出，则强制设置了一个该超时时间（单位毫秒），默认是600000 （10分钟）。如果你的程序对每条输入数据的处理时间过长，建议将 该参数调大。</li>
<li>如果可以不用Reduce，尽可能不用</li>
</ul>
<h4 id="MapReduce-数据倾斜问题"><a href="#MapReduce-数据倾斜问题" class="headerlink" title="MapReduce 数据倾斜问题"></a>MapReduce 数据倾斜问题</h4><blockquote>
<p>数据频率倾斜——某一个区域的数据量要远远大于其他区域。</p>
<p> 数据大小倾斜——部分记录的大小远远大于平均值。</p>
</blockquote>
<ol>
<li><p>先检查是否空值过多造成的数据倾斜可以直接过滤掉空值；如果想保留空值，就自定义分区，将空值加随机数打 散。最后再二次聚合。 </p>
</li>
<li><p>能在 map 阶段提前处理，最好先在 Map 阶段处理。如：Combiner、MapJoin </p>
</li>
<li><p>设置多个 reduce 个数</p>
</li>
</ol>
<h3 id="Hadoop-Yarn-生产经验"><a href="#Hadoop-Yarn-生产经验" class="headerlink" title="Hadoop-Yarn 生产经验"></a>Hadoop-Yarn 生产经验</h3><blockquote>
<p>参考Yarn笔记</p>
</blockquote>
<h2 id="本机Hadoop学习环境调优"><a href="#本机Hadoop学习环境调优" class="headerlink" title="本机Hadoop学习环境调优"></a>本机Hadoop学习环境调优</h2><blockquote>
<p>虚拟机配置：<br>        4G内存<br>        2核<br>        50G磁盘</p>
<p>使用场景：<br>        多是处理小文件</p>
</blockquote>
<h3 id="HDFS-参数调优"><a href="#HDFS-参数调优" class="headerlink" title="HDFS 参数调优"></a>HDFS 参数调优</h3><p>修改：hadoop-env.sh</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HDFS_NAMENODE_OPTS=&quot;-Dhadoop.security.logger=INFO,RFAS -Xmx1024m&quot;</span><br><span class="line">export HDFS_DATANODE_OPTS=&quot;-Dhadoop.security.logger=ERROR,RFAS -Xmx1024m&quot;</span><br></pre></td></tr></table></figure>

<p>修改 hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- NameNode 有一个工作线程池，默认值是 10 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.handler.count<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>21<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>修改 core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置垃圾回收时间为 60 分钟 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>分发配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xsync hadoop-env.sh hdfs-site.xml core-site.xml</span><br></pre></td></tr></table></figure>

<h3 id="MapReduce-参数调优"><a href="#MapReduce-参数调优" class="headerlink" title="MapReduce 参数调优"></a>MapReduce 参数调优</h3><p>修改 mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 环形缓冲区大小，默认 100m --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.task.io.sort.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 环形缓冲区溢写阈值，默认 0.8 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.sort.spill.percent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.80<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- merge 合并次数，默认 10 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.task.io.sort.factor<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- maptask 内存，默认 1g； maptask 堆内存大小默认和该值大小一致</span></span><br><span class="line"><span class="comment">mapreduce.map.java.opts --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The amount of memory to request from the scheduler for each map task. If this is not specified or is non-positive, it is inferred from mapreduce.map.java.opts and mapreduce.job.heap.memory-mb.ratio. If java-opts are also not specified, we set it to 1024.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- matask 的 CPU 核数，默认 1 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- matask 异常重试次数，默认 4 次 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.maxattempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 每个 Reduce 去 Map 中拉取数据的并行数。默认值是 5 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.shuffle.parallelcopies<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Buffer 大小占 Reduce 可用内存的比例，默认值 0.7 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.shuffle.input.buffer.percent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.70<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Buffer 中的数据达到多少比例开始写入磁盘，默认值 0.66。 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.shuffle.merge.percent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.66<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- reducetask 内存，默认 1g；reducetask 堆内存大小默认和该值大小一致</span></span><br><span class="line"><span class="comment">mapreduce.reduce.java.opts --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>The amount of memory to request from the scheduler for each reduce task. If this is not specified or is non-positive, it is inferred from mapreduce.reduce.java.opts and mapreduce.job.heap.memory-mb.ratio. If java-opts are also not specified, we set it to 1024.</span><br><span class="line">     <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- reducetask 的 CPU 核数，默认 1 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- reducetask 失败重试次数，默认 4 次 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.maxattempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 当 MapTask 完成的比例达到该值后才会为 ReduceTask 申请资源。默认是 0.05</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.reduce.slowstart.completedmaps<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.05<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 如果程序在规定的默认 10 分钟内没有读到数据，将强制超时退出 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.task.timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>600000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="Yarn-参数调优"><a href="#Yarn-参数调优" class="headerlink" title="Yarn 参数调优"></a>Yarn 参数调优</h3><p>修改 yarn-site.xml </p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 选择调度器，默认容量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The class to use as the resource scheduler.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- ResourceManager 处理调度器请求的线程数量,默认 50；如果提交的任务数大于 50，可以</span></span><br><span class="line"><span class="comment">增加该值，但是不能超过 3 台 * 2 线程 = 6 线程（去除其他应用程序实际不能超过 3） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Number of threads to handle scheduler interface.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.client.thread-count<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 是否让 yarn 自动检测硬件进行配置，默认是 false，如果该节点有很多其他应用程序，建议</span></span><br><span class="line"><span class="comment">手动配置。如果该节点没有其他应用程序，可以采用自动 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Enable auto-detection of node capabilities such as memory and CPU.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.detect-hardware-capabilities<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 是否将虚拟核数当作 CPU 核数，默认是 false，采用物理 CPU 核数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Flag to determine if logical processors(such as hyperthreads) should be counted as cores. Only applicable on Linux when yarn.nodemanager.resource.cpu-vcores is set to -1 and yarn.nodemanager.resource.detect-hardware-capabilities is true.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.count-logical-processors-ascores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 虚拟核数和物理核数乘数，默认是 1.0 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Multiplier to determine how to convert phyiscal cores to vcores. This value is used if yarn.nodemanager.resource.cpu-vcores is set to -1(which implies auto-calculate vcores) and yarn.nodemanager.resource.detect-hardware-capabilities is set to true. The number of vcores will be calculated as number of CPUs * multiplier.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.pcores-vcores-multiplier<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- NodeManager 使用内存数，默认 8G，修改为 4G 内存 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Amount of physical memory, in MB, that can be allocated for containers. If set to -1 and yarn.nodemanager.resource.detect-hardware-capabilities is true, it is automatically calculated(in case of Windows and Linux).In other cases, the default is 8192MB.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nodemanager 的 CPU 核数，不按照硬件环境自动设定时默认是 8 个，修改为 2 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Number of vcores that can be allocated for containers. This is used by the RM scheduler when allocating resources for containers. This is not used to limit the number of CPUs used by YARN containers. If it is set to -1 and yarn.nodemanager.resource.detect-hardware-capabilities is true, it is automatically determined from the hardware in case of Windows and Linux.In other cases, number of vcores is 8 by default.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 容器最小内存，默认 1G --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The minimum allocation for every container request at the RM in MBs. Memory requests lower than this will be set to the value of this property. Additionally, a node manager that is configured to have less memory than this value will be shut down by the resource manager.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 容器最大内存，默认 8G，修改为 2G --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum allocation for every container request at the RM in MBs. Memory requests higher than this will throw an InvalidResourceRequestException.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 容器最小 CPU 核数，默认 1 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The minimum allocation for every container request at the RM in terms of virtual CPU cores. Requests lower than this will be set to the value of this property. Additionally, a node manager that is configured to have fewer virtual cores than this value will be shut down by the resource manager.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 容器最大 CPU 核数，默认 4 个，修改为 2 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum allocation for every container request at the RM in terms of virtual CPU cores. Requests higher than this will throw an InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 虚拟内存检查，默认打开，修改为关闭 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether virtual memory limits will be enforced for containers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 虚拟内存和物理内存设置比例,默认 2.1 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Ratio between virtual memory to physical memory when setting memory limits for containers. Container allocations are expressed in terms of physical memory, and virtual memory usage is allowed to exceed this allocation by this ratio.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2.1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>搭建平台</tag>
        <tag>基础知识</tag>
      </tags>
  </entry>
</search>
